{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((134, 19), (66, 19), (134,), (66,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"../data/Advertising.csv\", index_col=0)\n",
    "\n",
    "X, y = df.drop(\"Sales\", axis=\"columns\"), df[\"Sales\"]\n",
    "\n",
    "model_polynomial = PolynomialFeatures(3, include_bias=False)\n",
    "poly_feature = model_polynomial.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_feature, y, test_size=0.33, random_state=1337)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00, 0.03\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"{scaled_X_train.mean():.2f}, {scaled_X_test.mean():.2f}\")     # Så nära 0 som möjligt är bra\n",
    "\n",
    "# Datan är nu skalad för att få std (standard deviation) = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24959538036150153, 0.49959521651182925)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge regression för att minska variansen\n",
    "\n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# L2 regularization\n",
    "\n",
    "# alpha = lambda \n",
    "\n",
    "model_ridge = Ridge(alpha=0.1)\n",
    "model_ridge.fit(scaled_X_train, y_train) # .fit innebär att man tränar algoritmen på datan\n",
    "\n",
    "# Y_hat = Y_pred\n",
    "y_hat = model_ridge.predict(scaled_X_test) # Y_hat = en vektor på förutsägelsen\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_hat) # Avståndet mellan  y_test och y_hat i kvadrat, (felet)\n",
    "RMSE = np.sqrt(MSE) # Units, i detta exempel en halv unit i fel\n",
    "\n",
    "\n",
    "MSE, RMSE\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.77053674  0.16177077  0.         -0.          3.77413423  0.\n",
      "  0.          0.04720898  0.         -0.37585383 -0.         -0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7738198161795438"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model_lasso = Lasso(alpha=0.1)\n",
    "model_lasso.fit(scaled_X_train, y_train)\n",
    "Y_hat = model_lasso.predict(scaled_X_test)\n",
    "\n",
    "print(model_lasso.coef_)\n",
    "\n",
    "np.sqrt(mean_squared_error(y_test, Y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7.34985134   0.6331339    0.4575767  -10.6664558    4.69979729\n",
      "  -1.21795087  -0.33002651  -0.2049405   -0.18235904   5.19374784\n",
      "  -1.37857412   1.00487749   0.51536908  -0.39391912   0.23265959\n",
      "  -0.28009281   0.38741237   0.14013473  -0.09899025] \n",
      " \n",
      " 0.9912715899638569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "model_ridgeCV = RidgeCV(alphas=[.0001, .001, .01, .1, .5, 1, 5, 10], scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "model_ridgeCV.fit(scaled_X_train, y_train)\n",
    "\n",
    "# Score ska vara högt, Hur mycket av variansen som förklaras av modellen\n",
    "# 99% av våra värden ligger innanför\n",
    "print(model_ridgeCV.coef_, \"\\n \\n\", model_ridgeCV.score(scaled_X_train, y_train)) \n",
    "model_ridgeCV.alpha_\n",
    "\n",
    "# Våran träningsdata är väldigt varierande eftersom om vi ändrar randomstate i början så blir resultatet här \n",
    "# på vilken alpha  som är bäst väldigt annorlunda \n",
    "\n",
    "# Denna polynomiella funktion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha (lambda) = 0.004956246150210799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4529065286091838"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "model_lassoCV = LassoCV(eps=0.001, n_alphas= 100, max_iter=10000, cv=5)\n",
    "model_lassoCV.fit(scaled_X_train, y_train)\n",
    "\n",
    "print(f\"alpha (lambda) = {model_lassoCV.alpha_}\")\n",
    "\n",
    "y_hat = model_lassoCV.predict(scaled_X_test)\n",
    "\n",
    "np.sqrt(mean_squared_error(y_test, y_hat)) # RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 ratio = 1.0 : alpha (lambda) = 0.004956246150210799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4529065286091838"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "# eps = \"steglängden\", epsilon. \n",
    "\n",
    "model_elasticCV = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1, 1], eps=0.001, n_alphas=100, max_iter=10000, cv=5)\n",
    "model_elasticCV.fit(scaled_X_train, y_train)\n",
    "\n",
    "print(f\"l1 ratio = {model_elasticCV.l1_ratio_} : alpha (lambda) = {model_elasticCV.alpha_}\")\n",
    "\n",
    "y_hat = model_elasticCV.predict(scaled_X_test) # prediktering med våran tränade modell \"model_elasticCV\"\n",
    "\n",
    "np.sqrt(mean_squared_error(y_test, y_hat))\n",
    "\n",
    "# Testar alla l1_ratio och vi kom fram till med kors-valideringen i elasticnetCV att 1.0 varden bästa ration för modellen\n",
    "\n",
    "# Vi tar allt från lasso i detta fall, elastic net testar båda. Hade vi fått l1 = 0.5 hade vi tagit hälften av varje modell (ridge, lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Rasmus-Berghall-Q4tY2P30",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
